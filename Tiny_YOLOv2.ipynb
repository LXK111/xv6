{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv2-Tiny\n",
    "This notebook shows an example of object detection of an image.\n",
    "The network that is used for inference is a variant of Tiny-Yolov2, whose topology is illustrated in the following picture.\n",
    "The pynq colored layers will be executed in python, while the other layers are executed in the HW accelerator.\n",
    "\n",
    "The image processing is performed within darknet by using python bindings.\n",
    "\n",
    "\n",
    "![Tinier-YOLO-topology](Tinier-YOLO-topology.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pynq import Overlay\n",
    "import numpy as np\n",
    "from pynq import Xlnk\n",
    "import struct\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积和池化驱动\n",
    "def RunConv(conv,Kx,Ky,Sx,Sy,mode,relu_en,feature_in,W,bias,feature_out):\n",
    "    conv.write(0x10,feature_in.shape[2]);\n",
    "    conv.write(0x18,feature_in.shape[0]);\n",
    "    conv.write(0x20,feature_in.shape[1]);\n",
    "    conv.write(0x28,feature_out.shape[2]);\n",
    "    conv.write(0x30,Kx);\n",
    "    conv.write(0x38,Ky);\n",
    "    conv.write(0x40,Sx);\n",
    "    conv.write(0x48,Sy);\n",
    "    conv.write(0x50,mode);\n",
    "    conv.write(0x58,relu_en);\n",
    "    conv.write(0x60,feature_in.physical_address);\n",
    "    conv.write(0x68,W.physical_address);\n",
    "    conv.write(0x70,bias.physical_address);\n",
    "    conv.write(0x78,feature_out.physical_address);\n",
    "    conv.write(0, (conv.read(0)&0x80)|0x01 );\n",
    "    tp=conv.read(0)\n",
    "    while not ((tp>>1)&0x1):\n",
    "        tp=conv.read(0);\n",
    "\n",
    "def RunPool(pool,Kx,Ky,mode,feature_in,feature_out):\n",
    "    pool.write(0x10,feature_in.shape[2]);\n",
    "    pool.write(0x18,feature_in.shape[0]);\n",
    "    pool.write(0x20,feature_in.shape[1]);\n",
    "    pool.write(0x28,Kx);\n",
    "    pool.write(0x30,Ky);\n",
    "    pool.write(0x38,mode);\n",
    "    pool.write(0x40,feature_in.physical_address);\n",
    "    pool.write(0x48,feature_out.physical_address);\n",
    "    pool.write(0, (pool.read(0)&0x80)|0x01 );\n",
    "    while not ((pool.read(0)>>1)&0x1):\n",
    "        pass;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pynq/overlay.py:299: UserWarning: Users will not get PARAMETERS / REGISTERS information through TCL files. HWH file is recommended.\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlay download finish\n"
     ]
    }
   ],
   "source": [
    "# 下载比特流文件，加载卷积和池化IP核\n",
    "xlnk=Xlnk();\n",
    "ol=Overlay(\"base.bit\")\n",
    "ol.download()\n",
    "conv_ip=ol.Conv_0\n",
    "pool_ip=ol.Pool_0\n",
    "print(\"Overlay download finish\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调用卷积和池化IP核，执行第五层卷积层和最大池化层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入第四层最大池化层的输出特征值\n",
    "# 导入第五层卷积层的权重\n",
    "feature = np.loadtxt('./feature_output/max4_output.txt').astype(np.float32)\n",
    "load_weights = np.loadtxt('./weights/w5.txt').astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07303499999997598\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "# reshape 第四层最大池化层特征值，拷贝到第五层卷积层的输入特征值\n",
    "feature = np.reshape(feature,(26,26,128))\n",
    "conv5_in = xlnk.cma_array(shape=(26,26,128),cacheable=0,dtype=np.float32)\n",
    "np.copyto(conv5_in,feature)\n",
    "\n",
    "# 为weights、bias和cov5_output分配连续的物理地址空间\n",
    "weights = xlnk.cma_array(shape=(3,3,128,256),cacheable=0,dtype=np.float32)\n",
    "bias = xlnk.cma_array(shape=(256),cacheable=0,dtype=np.float32)\n",
    "conv5_output = xlnk.cma_array(shape=(26,26,256),cacheable=0,dtype=np.float32)\n",
    "\n",
    "# reshape 权重值，拷贝给第五层卷积层的权重weights\n",
    "load_weights = np.reshape(load_weights,(3,3,128,256))\n",
    "np.copyto(weights,load_weights)\n",
    "\n",
    "# 导入第五层卷积层的bias\n",
    "load_bias = np.loadtxt('./bias/b5.txt')\n",
    "np.copyto(bias,load_bias)\n",
    "\n",
    "end = time.clock()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.18962300000001\n"
     ]
    }
   ],
   "source": [
    "# 执行第五层卷积层IP核\n",
    "start = time.clock()\n",
    "RunConv(conv_ip,3,3,1,1,1,0,conv5_in,weights,bias,conv5_output)\n",
    "end = time.clock()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10497600000002194\n"
     ]
    }
   ],
   "source": [
    "# 为第五层最大池化层的输出特征值分配连续的物理地址空间\n",
    "pool5_output = xlnk.cma_array(shape=(13,13,256),cacheable=0,dtype=np.float32)\n",
    "\n",
    "# 执行第五层池化层IP核\n",
    "start = time.clock()\n",
    "RunPool(pool_ip,2,2,2,conv5_output,pool5_output)\n",
    "end = time.clock()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调用卷积和池化IP核，执行第九层全连接层，用python执行后处理程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入第八层最大池化层的输出特征值\n",
    "# 导入第九层全连接层的权重\n",
    "feature = np.loadtxt('./feature_output/conv8_output.txt').astype(np.float32)\n",
    "load_weights = np.loadtxt('./weights/w9.txt').astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0489629999999579\n"
     ]
    }
   ],
   "source": [
    "# reshape 第八层卷积层特征值，拷贝到第九层全连接层的输入特征值\n",
    "start = time.clock()\n",
    "feature = np.reshape(feature,(13,13,1024))\n",
    "conv9_in = xlnk.cma_array(shape=(13,13,1024),cacheable=0,dtype=np.float32)\n",
    "np.copyto(conv9_in,feature)\n",
    "\n",
    "# 为weights、bias和cov9_output分配连续的物理地址空间\n",
    "weights = xlnk.cma_array(shape=(1,1,1024,125),cacheable=0,dtype=np.float32)\n",
    "bias = xlnk.cma_array(shape=(125),cacheable=0,dtype=np.float32)\n",
    "output = xlnk.cma_array(shape=(13,13,125),cacheable=0,dtype=np.float32)\n",
    "\n",
    "# reshape 权重值，拷贝给第九层全连接层的权重weights\n",
    "load_weights = np.reshape(load_weights,(1,1,1024,125))\n",
    "np.copyto(weights,load_weights)\n",
    "\n",
    "# 导入第九层全连接层的bias\n",
    "load_bias = np.loadtxt('./bias/b9.txt')\n",
    "np.copyto(bias,load_bias)\n",
    "\n",
    "end = time.clock()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.623809000000051\n"
     ]
    }
   ],
   "source": [
    "# 执行第九层全连接层IP核，conv9 output需要去量化\n",
    "start = time.clock()\n",
    "RunConv(conv_ip,1,1,1,1,1,0,conv9_in,weights,bias,output)\n",
    "end = time.clock()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "import random\n",
    "from math import exp\n",
    "\n",
    "#sigmoid函数，用于神经网络激活函数，将变量映射到0,1之间\n",
    "def sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "#softmax逻辑回归，在yolo中用于将20种分类概率转换为一个概率值\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    out = e_x / e_x.sum()\n",
    "    return out\n",
    "\n",
    "#YOLO最后输出特征为13*13*125，转换为13*13*5*25之后用decode函数把输出特征还原为目标位置和概率\n",
    "#13*13*5*25表示将图片划分为13*13个网格，每个网格输出5个表示目标位置的边界框，每个框对应25个参数\n",
    "def decode(feature):\n",
    "    #anchors表示5个边界框的初始尺寸\n",
    "    anchors = [1.08,1.19,  3.42,4.41,  6.63,11.38,  9.42,5.11,  16.62,10.52]\n",
    "    #每个框的25个参数中前4个表示框的位置\n",
    "    x_offset = sigmoid(feature[:,:,:,0])\n",
    "    y_offset = sigmoid(feature[:,:,:,1])\n",
    "    w_offset = feature[:,:,:,2]\n",
    "    h_offset = feature[:,:,:,3]\n",
    "    class_probs = np.zeros((13,13,5,20),dtype=np.float32)\n",
    "    obj_probs = np.zeros((13,13,5),dtype=np.float32)\n",
    "    for i in range(0,13):\n",
    "        for j in range(0,13):\n",
    "            for k in range(0,5):\n",
    "                w_offset[i][j][k] = exp(w_offset[i][j][k])\n",
    "                h_offset[i][j][k] = exp(h_offset[i][j][k])\n",
    "                #第5个参数表示框内有目标的概率，后20个表示框内图像对应20中类别的概率\n",
    "                class_probs[i][j][k] = softmax(feature[i,j,k,5:])\n",
    "                obj_probs[i][j][k] = sigmoid(feature[i][j][k][4])\n",
    "                \n",
    "    x_cell = np.zeros((13,13),dtype=np.float32)\n",
    "    y_cell = np.zeros((13,13),dtype=np.float32)\n",
    "    \n",
    "    for i in range(0,13):\n",
    "        for j in range(0,13):\n",
    "            x_cell[i][j] = j\n",
    "            y_cell[i][j] = i\n",
    "    x_cell = np.reshape(x_cell,(13,13,1))\n",
    "    y_cell = np.reshape(y_cell,(13,13,1))\n",
    "    bbox_x = np.zeros((13,13,5),dtype=np.float32)\n",
    "    bbox_y = np.zeros((13,13,5),dtype=np.float32)\n",
    "    bbox_w = np.zeros((13,13,5),dtype=np.float32)\n",
    "    bbox_h = np.zeros((13,13,5),dtype=np.float32)\n",
    "    #将框的位置参数还原为框在图片上的坐标\n",
    "    for i in range(0,13):\n",
    "        for j in range(0,13):\n",
    "            for k in range(0,5):\n",
    "                bbox_x[i][j][k] = (x_cell[i][j][0] + x_offset[i][j][k]) / 13\n",
    "                bbox_y[i][j][k] = (y_cell[i][j][0] + y_offset[i][j][k]) / 13\n",
    "    for i in range(0,13):\n",
    "        for j in range(0,13):\n",
    "            for k in range(0,5):\n",
    "                bbox_w[i][j][k] = (anchors[2*k] * w_offset[i][j][k]) / 13\n",
    "                bbox_h[i][j][k] = (anchors[2*k+1] * h_offset[i][j][k]) / 13\n",
    "    bboxes = np.stack([bbox_x-bbox_w/2, bbox_y-bbox_h/2,bbox_x+bbox_w/2, bbox_y+bbox_h/2],axis=3)\n",
    "    return bboxes, class_probs, obj_probs\n",
    "\n",
    "#bboxes_cut函数用于将超出图片范围的框截断\n",
    "def bboxes_cut(bbox_min_max,bboxes):\n",
    "\tbboxes = np.copy(bboxes)\n",
    "\tbboxes = np.transpose(bboxes)\n",
    "\tbbox_min_max = np.transpose(bbox_min_max)\n",
    "\tbboxes[0] = np.maximum(bboxes[0],bbox_min_max[0])\n",
    "\tbboxes[1] = np.maximum(bboxes[1],bbox_min_max[1])\n",
    "\tbboxes[2] = np.minimum(bboxes[2],bbox_min_max[2])\n",
    "\tbboxes[3] = np.minimum(bboxes[3],bbox_min_max[3])\n",
    "\tbboxes = np.transpose(bboxes)\n",
    "\treturn bboxes\n",
    "\n",
    "#把框按评分排序，去掉评分低的框，只留下20个\n",
    "def bboxes_sort(classes,scores,bboxes,top_k=20):\n",
    "\tindex = np.argsort(-scores)\n",
    "\tclasses = classes[index][:top_k]\n",
    "\tscores = scores[index][:top_k]\n",
    "\tbboxes = bboxes[index][:top_k]\n",
    "\treturn classes,scores,bboxes\n",
    "\n",
    "#计算两个框的IOU值，表示它们之间的重合度\n",
    "def bboxes_iou(bboxes1,bboxes2):\n",
    "\tbboxes1 = np.transpose(bboxes1)\n",
    "\tbboxes2 = np.transpose(bboxes2)\n",
    "\n",
    "\tint_ymin = np.maximum(bboxes1[0], bboxes2[0])\n",
    "\tint_xmin = np.maximum(bboxes1[1], bboxes2[1])\n",
    "\tint_ymax = np.minimum(bboxes1[2], bboxes2[2])\n",
    "\tint_xmax = np.minimum(bboxes1[3], bboxes2[3])\n",
    "\n",
    "\tint_h = np.maximum(int_ymax-int_ymin,0.)\n",
    "\tint_w = np.maximum(int_xmax-int_xmin,0.)\n",
    "\n",
    "\tint_vol = int_h * int_w\n",
    "\tvol1 = (bboxes1[2] - bboxes1[0]) * (bboxes1[3] - bboxes1[1])\n",
    "\tvol2 = (bboxes2[2] - bboxes2[0]) * (bboxes2[3] - bboxes2[1])\n",
    "\tIOU = int_vol / (vol1 + vol2 - int_vol)\n",
    "\treturn IOU\n",
    "\n",
    "#非极大值抑制，将重合度高的几个框中评分低的消去，只留下评分高的\n",
    "def bboxes_nms(classes, scores, bboxes, nms_threshold=0.3):\n",
    "\tkeep_bboxes = np.ones(scores.shape, dtype=np.bool)\n",
    "\tfor i in range(scores.size-1):\n",
    "\t\tif keep_bboxes[i]:\n",
    "\t\t\toverlap = bboxes_iou(bboxes[i], bboxes[(i+1):])\n",
    "\t\t\tkeep_overlap = np.logical_or(overlap < nms_threshold, classes[(i+1):] != classes[i])\n",
    "\t\t\tkeep_bboxes[(i+1):] = np.logical_and(keep_bboxes[(i+1):], keep_overlap)\n",
    "\n",
    "\tidxes = np.where(keep_bboxes)\n",
    "\treturn classes[idxes], scores[idxes], bboxes[idxes]\n",
    "\n",
    "#后处理程序\n",
    "def postprocess(bboxes,obj_probs,class_probs,image_shape=(416,416),threshold=0.3):\n",
    "\tbboxes = np.reshape(bboxes,[-1,4])\n",
    "\tbboxes[:,0:1] *= float(image_shape[1])\n",
    "\tbboxes[:,1:2] *= float(image_shape[0])\n",
    "\tbboxes[:,2:3] *= float(image_shape[1])\n",
    "\tbboxes[:,3:4] *= float(image_shape[0])\n",
    "\tbboxes = bboxes.astype(np.int32)\n",
    "    #切割超出边界的框\n",
    "\tbbox_min_max = [0,0,image_shape[1]-1,image_shape[0]-1]\n",
    "\tbboxes = bboxes_cut(bbox_min_max,bboxes)\n",
    "\n",
    "\tobj_probs = np.reshape(obj_probs,[-1])\n",
    "\tclass_probs = np.reshape(class_probs,[len(obj_probs),-1])\n",
    "\tclass_max_index = np.argmax(class_probs,axis=1)\n",
    "\tclass_probs = class_probs[np.arange(len(obj_probs)),class_max_index]\n",
    "    #用有目标的置信度和分类置信度之积作为每一个框的最终评分\n",
    "\tscores = obj_probs * class_probs\n",
    "    #去掉评分小于threshold的框\n",
    "\tkeep_index = scores > threshold\n",
    "    #分类概率最大的种类即为框中目标的种类\n",
    "\tclass_max_index = class_max_index[keep_index]\n",
    "\tscores = scores[keep_index]\n",
    "\tbboxes = bboxes[keep_index]\n",
    "\n",
    "\tclass_max_index,scores,bboxes = bboxes_sort(class_max_index,scores,bboxes)\n",
    "\tclass_max_index,scores,bboxes = bboxes_nms(class_max_index,scores,bboxes)\n",
    "\n",
    "\treturn bboxes,scores,class_max_index\n",
    "#在原图中画出框，写出分类信息和评分\n",
    "def draw_detection(im, bboxes, scores, cls_inds, labels, thr=0.3):\n",
    "    #设置框颜色\n",
    "\thsv_tuples = [(x/float(len(labels)), 1., 1.)  for x in range(len(labels))]\n",
    "\tcolors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "\tcolors = list(\n",
    "\t\tmap(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),colors))\n",
    "\trandom.seed(10101)\n",
    "\trandom.shuffle(colors)\n",
    "\trandom.seed(None) \n",
    "\t# draw image\n",
    "\timgcv = np.copy(im)\n",
    "\th, w, _ = imgcv.shape\n",
    "\tfor i, box in enumerate(bboxes):\n",
    "\t\tif scores[i] < thr:\n",
    "\t\t\tcontinue\n",
    "\t\tcls_indx = cls_inds[i]\n",
    "\n",
    "\t\tthick = int((h + w) / 300)\n",
    "        #画框\n",
    "\t\tcv2.rectangle(imgcv,(box[0], box[1]), (box[2], box[3]),colors[cls_indx], thick)\n",
    "\t\tmess = '%s: %.3f' % (labels[cls_indx], scores[i])\n",
    "\t\tif box[1] < 20:\n",
    "\t\t\ttext_loc = (box[0] + 2, box[1] + 15)\n",
    "\t\telse:\n",
    "\t\t\ttext_loc = (box[0], box[1] - 10)\n",
    "        #写字\n",
    "\t\tcv2.putText(imgcv, mess, text_loc, cv2.FONT_HERSHEY_SIMPLEX, 1e-3*h, (255,255,255), thick//3)\n",
    "\treturn imgcv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#输出特征转换为13,13,5,25尺寸\n",
    "output = np.reshape(output,(13,13,5,25))\n",
    "#读取原图并转换为与输出特征匹配的尺寸\n",
    "image1 = cv2.imread(\"dog.jpg\")\n",
    "image1 = cv2.resize(image1,(416,416),interpolation=cv2.INTER_CUBIC)\n",
    "#将输出特征还原为目标位置和评分\n",
    "bboxes, class_p, obj_p = decode(output)\n",
    "bboxes, scores, class_max_index = postprocess(bboxes,obj_p,class_p)\n",
    "#画框，保存\n",
    "class_names = [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "img_detection = draw_detection(image1, bboxes, scores, class_max_index, class_names)\n",
    "cv2.imwrite('output.jpg',img_detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dog](dog.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![output](output.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
